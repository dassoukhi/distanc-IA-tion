{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.1.48-cp38-cp38-macosx_10_13_x86_64.whl (40.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/francois/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.1.48\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/francois/Library/Caches/pip/wheels/59/1b/52/0dea905f8278d5514dc4d0be5e251967f8681670cadd3dca89/imutils-0.5.4-py3-none-any.whl\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avant d'exécuter ce fichier, assurez-vous que vous avez le dossier Pretrained model et classes\n",
    "#vous pouvez tout obtenir via mon lien github que je mentionnerai ci-dessous\n",
    "# Cela dépendra des performances du processeur si les performances de votre processeur sont bonnes,\n",
    "# la vidéo sera traitée rapidement # je ne l'ai pas bonne performance cpu à ce pourquoi son traitement assez faible\n",
    "import cv2\n",
    "# openCV est utilisé pour toutes sortes d'analyses d'images et de vidéos,\n",
    "# telles que la reconnaissance et la détection faciales, la lecture de plaques d'immatriculation,\n",
    "# l'édition de photos, la vision robotique avancée, la reconnaissance optique de caractères, et bien plus encore.\n",
    "import datetime\n",
    "# Le module datetime permet de manipuler les dates et les heures.\n",
    "import imutils\n",
    "# imutis compose une série de fonctions pratiques pour rendre les fonctions de traitement d'image de base telles que\n",
    "# la traduction,la rotation, le redimensionnement, le squelette, l'affichage des images Matplotlib, le tri des contours,\n",
    "# la détection des bords et bien plus encore avec OpenCV et Python .\n",
    "\n",
    "import numpy as np\n",
    "# NumPy est une extension du langage de programmation Python,\n",
    "# destinée à manipuler des matrices ou tableaux multidimensionnels ainsi que\n",
    "# des fonctions mathématiques opérant sur ces tableaux\n",
    "from centroidtracker import CentroidTracker\n",
    "from itertools import combinations\n",
    "#Ce module implémente de nombreuses briques d'itérateurs rapides et efficaces pour boucler efficacement\n",
    "import math\n",
    "# Ce module math permet d'accéder aux fonctions mathématiques définies par le standard C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le modèle et les fichiers prototypes sont ici\n",
    "protopath = \"MobileNetSSD_deploy.prototxt\"\n",
    "modelpath = \"MobileNetSSD_deploy.caffemodel\"\n",
    "\n",
    "# modelConfiguration = \"C:\\\\Users\\\\Dass\\Desktop\\\\test\\\\Computer-Vision\\\\Social_distancing\\\\yolov3.cfg\"\n",
    "# modelWeight = \"C:\\\\Users\\\\Dass\\\\Desktop\\\\test\\\\Computer-Vision\\\\Social_distancing\\\\yolov3.weights\"\n",
    "#\n",
    "detector = cv2.dnn.readNetFromCaffe(prototxt=protopath, caffeModel=modelpath)\n",
    "\n",
    "# detector = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeight)\n",
    "# detector.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "#mention du nombre de classes ici\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
    "           \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "tracker = CentroidTracker(maxDisappeared=40, maxDistance=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    try:\n",
    "        if len(boxes) == 0:\n",
    "            return []\n",
    "\n",
    "        if boxes.dtype.kind == \"i\":\n",
    "            boxes = boxes.astype(\"float\")\n",
    "\n",
    "        pick = []\n",
    "\n",
    "        x1 = boxes[:, 0]\n",
    "        y1 = boxes[:, 1]\n",
    "        x2 = boxes[:, 2]\n",
    "        y2 = boxes[:, 3]\n",
    "\n",
    "        area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        while len(idxs) > 0:\n",
    "            last = len(idxs) - 1\n",
    "            i = idxs[last]\n",
    "            pick.append(i)\n",
    "\n",
    "            xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "            yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "            xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "            yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "            w = np.maximum(0, xx2 - xx1 + 1)\n",
    "            h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "            overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "            idxs = np.delete(idxs, np.concatenate(([last],\n",
    "                                                   np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "        return boxes[pick].astype(\"int\")\n",
    "    except Exception as e:\n",
    "        print(\"Exception occurred in non_max_suppression : {}\".format(e))\n",
    "#Passez le lien vidéo ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #ouverture de la video avec openCv\n",
    "\n",
    "    cap = cv2.VideoCapture('vid_short.mp4')\n",
    "\n",
    "    #cap = cv2.VideoCapture(0)\n",
    "\n",
    "    #prendre l'heure actuelle d'images par seconde avant l'execution\n",
    "    fps_start_time = datetime.datetime.now()\n",
    "    # fps = images par seconde // initié à 0\n",
    "    fps = 0\n",
    "    # nombre total d'images\n",
    "    total_frames = 0\n",
    "    # boucle de traitement de la video\n",
    "    while True:\n",
    "        # ici on la video image par image\n",
    "        ret, frame = cap.read()\n",
    "        # on redimensionne l'image d'une largeur de 600 px\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        # on increment total_frames de 1\n",
    "        total_frames = total_frames + 1\n",
    "\n",
    "        (H, W) = frame.shape[:2]\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.007843, (W, H), 127.5)\n",
    "\n",
    "        detector.setInput(blob)\n",
    "        person_detections = detector.forward()\n",
    "        rects = []\n",
    "        for i in np.arange(0, person_detections.shape[2]):\n",
    "            confidence = person_detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:\n",
    "                idx = int(person_detections[0, 0, i, 1])\n",
    "\n",
    "                if CLASSES[idx] != \"person\":\n",
    "                    continue\n",
    "\n",
    "                person_box = person_detections[0, 0, i, 3:7] * np.array([W, H, W, H])\n",
    "                (startX, startY, endX, endY) = person_box.astype(\"int\")\n",
    "                rects.append(person_box)\n",
    "\n",
    "        boundingboxes = np.array(rects)\n",
    "        boundingboxes = boundingboxes.astype(int)\n",
    "        rects = non_max_suppression_fast(boundingboxes, 0.3)\n",
    "        centroid_dict = dict()\n",
    "        objects = tracker.update(rects)\n",
    "        for (objectId, bbox) in objects.items():\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            x1 = int(x1)\n",
    "            y1 = int(y1)\n",
    "            x2 = int(x2)\n",
    "            y2 = int(y2)\n",
    "            cX = int((x1 + x2) / 2.0)\n",
    "            cY = int((y1 + y2) / 2.0)\n",
    "\n",
    "\n",
    "            centroid_dict[objectId] = (cX, cY, x1, y1, x2, y2)\n",
    "\n",
    "            # text = \"ID: {}\".format(objectId)\n",
    "            # cv2.putText(frame, text, (x1, y1-5), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "            \n",
    "        red_zone_list = []\n",
    "        for (id1, p1), (id2, p2) in combinations(centroid_dict.items(), 2):\n",
    "            dx, dy = p1[0] - p2[0], p1[1] - p2[1]\n",
    "            distance = math.sqrt(dx * dx + dy * dy)\n",
    "            if distance < 75.0:\n",
    "                if id1 not in red_zone_list:\n",
    "                    red_zone_list.append(id1)\n",
    "                if id2 not in red_zone_list:\n",
    "                    red_zone_list.append(id2)\n",
    "\n",
    "        for id, box in centroid_dict.items():\n",
    "            if id in red_zone_list:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 0, 255), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (box[2], box[3]), (box[4], box[5]), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        fps_end_time = datetime.datetime.now()\n",
    "        time_diff = fps_end_time - fps_start_time\n",
    "        if time_diff.seconds == 0:\n",
    "            fps = 0.0\n",
    "        else:\n",
    "            fps = (total_frames / time_diff.seconds)\n",
    "\n",
    "        fps_text = \"FPS: {:.2f}\".format(fps)\n",
    "\n",
    "        cv2.putText(frame, fps_text, (5, 30), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Social_Distancing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "# SciPy est un projet visant à unifier et fédérer un ensemble de bibliothèques Python à usage scientifique.\n",
    "# Scipy utilise les tableaux et matrices du module NumPy donc il depend de NumPy\n",
    "# Scipy.spatial peut calculer des triangulations, des diagrammes de Voronoi et\n",
    "# des coques convexes d'un ensemble de points, en utilisant la bibliothèque Qhull .\n",
    "# De plus, il contient des KDTree implémentations pour les requêtes de points du voisin le plus proche\n",
    "# et des utilitaires pour les calculs de distance dans diverses métriques.\n",
    "# distance permet le calcul de la matrice de distance à partir d'une collection de vecteurs d'observation\n",
    "# bruts stockés dans un tableau rectangulaire.\n",
    "from collections import OrderedDict\n",
    "# OrderedDict sont des dictionnaires qui possèdent des capacités supplémentaires pour s'ordonner\n",
    "#ils ont ont été conçus pour être performants dans les opérations de ré-arrangement.\n",
    "# L'occupation mémoire, la vitesse de parcours et les performances de mise à jour étaient secondaires\n",
    "# import numpy as np\n",
    "# NumPy est une extension du langage de programmation Python,\n",
    "# destinée à manipuler des matrices ou tableaux multidimensionnels ainsi que\n",
    "# des fonctions mathématiques opérant sur ces tableaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidTracker:\n",
    "    def __init__(self, maxDisappeared=50, maxDistance=50):\n",
    "        # initialise l'ID d'objet unique suivant avec deux\n",
    "        # dictionnaires utilisés pour suivre le mappage d'un objet donné\n",
    "        # ID à son point central et nombre d'images consécutives qu'il a\n",
    "        # a été marqué comme \"disparu\", respectivement\n",
    "        self.nextObjectID = 0\n",
    "        self.objects = OrderedDict()\n",
    "        self.disappeared = OrderedDict()\n",
    "        self.bbox = OrderedDict()  # CHANGE\n",
    "\n",
    "        # stocke le nombre d'images consécutives maximum pour une donnée\n",
    "        # objet peut être marqué comme \"disparu\" jusqu'à ce que nous\n",
    "        # aurons plus besoin de l'enregistrer dans la suite du traitement\n",
    "        self.maxDisappeared = maxDisappeared\n",
    "\n",
    "        # stocker la distance maximale entre les points centrals  à associer\n",
    "        # un objet - si la distance est supérieure à ce maximum\n",
    "        # distance, nous commencerons à marquer l'objet comme \"disparu\"\n",
    "        self.maxDistance = maxDistance\n",
    "\n",
    "    def register(self, centroid, inputRect):\n",
    "        # lors de l'enregistrement d'un objet, nous utilisons le prochain objet disponible\n",
    "        # ID pour stocker le point central\n",
    "        self.objects[self.nextObjectID] = centroid\n",
    "        self.bbox[self.nextObjectID] = inputRect  # CHANGE\n",
    "        self.disappeared[self.nextObjectID] = 0\n",
    "        self.nextObjectID += 1\n",
    "\n",
    "    def deregister(self, objectID):\n",
    "        # pour désenregistrer un ID d'objet, nous supprimons l'ID d'objet de\n",
    "        # nos deux dictionnaires respectifs\n",
    "        del self.objects[objectID]\n",
    "        del self.disappeared[objectID]\n",
    "        del self.bbox[objectID]  # CHANGE\n",
    "\n",
    "    def update(self, rects):\n",
    "        # vérifier pour voir si la liste des rectangles de boîte englobante d'entrée\n",
    "        # est vide\n",
    "        if len(rects) == 0:\n",
    "            # boucle sur tous les objets suivis existants et marque-les\n",
    "            # comme disparu\n",
    "            for objectID in list(self.disappeared.keys()):\n",
    "                self.disappeared[objectID] += 1\n",
    "\n",
    "                # si nous avons atteint un nombre maximum de\n",
    "                # cadres où un objet donné a été marqué comme\n",
    "                # manquant, désenregistrer(deregister)\n",
    "                if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                    self.deregister(objectID)\n",
    "\n",
    "            # revenir tôt car il n'y a pas de point central ou d'informations de suivi\n",
    "            # mettre à jour\n",
    "            # return self.objects\n",
    "            return self.bbox\n",
    "\n",
    "        # initialise un tableau de centroïdes(points centrals) d'entrée pour l'image courante\n",
    "        inputCentroids = np.zeros((len(rects), 2), dtype=\"int\")\n",
    "        inputRects = []\n",
    "        # boucle sur les rectangles de la boîte englobante\n",
    "        for (i, (startX, startY, endX, endY)) in enumerate(rects):\n",
    "            # utiliser les coordonnées de la boîte englobante pour dériver le point central\n",
    "            cX = int((startX + endX) / 2.0)\n",
    "            cY = int((startY + endY) / 2.0)\n",
    "            inputCentroids[i] = (cX, cY)\n",
    "            inputRects.append(rects[i])  # CHANGE\n",
    "\n",
    "        # si nous ne suivons actuellement aucun objet, prenez l'entrée\n",
    "        # centroids(point centraux) et enregistrez chacun d'eux\n",
    "        if len(self.objects) == 0:\n",
    "            for i in range(0, len(inputCentroids)):\n",
    "                self.register(inputCentroids[i], inputRects[i])  # CHANGE\n",
    "\n",
    "        # sinon, des objets sont qui sont en suivi, alors nous devons donc\n",
    "        # essayez de faire correspondre les point centraux d'entrée à l'objet existant\n",
    "        # centroids\n",
    "        else:\n",
    "            # récupérer l'ensemble des ID d'objet et des centres de gravité correspondants\n",
    "            objectIDs = list(self.objects.keys())\n",
    "            objectCentroids = list(self.objects.values())\n",
    "\n",
    "            # calculer la distance entre chaque paire d'objets\n",
    "            # centroids et centroids d'entrée, respectivement - notre\n",
    "            # objectif sera de faire correspondre un point central d'entrée à un\n",
    "            # centre de l'objet\n",
    "            D = dist.cdist(np.array(objectCentroids), inputCentroids)\n",
    "\n",
    "            # pour effectuer cette correspondance, nous devons (1) trouver la\n",
    "            # plus petite valeur de chaque ligne, puis (2) trier la ligne\n",
    "            # index en fonction de leurs valeurs minimales afin que la ligne\n",
    "            # avec la plus petite valeur seront stockées en tête de la\n",
    "            # liste\n",
    "            rows = D.min(axis=1).argsort()\n",
    "\n",
    "            # ensuite, nous effectuons un processus similaire sur les colonnes en\n",
    "            # trouver la plus petite valeur dans chaque colonne puis\n",
    "            # trier à l'aide de la liste d'index des lignes précédemment calculée\n",
    "            cols = D.argmin(axis=1)[rows]\n",
    "\n",
    "            # afin de déterminer si nous devons mettre à jour, enregistrer(register function),\n",
    "            # ou désenregistrer(deregister function) un objet dont nous devons garder la trace\n",
    "            # des lignes et des index de colonnes que nous avons déjà examinés\n",
    "            usedRows = set()\n",
    "            usedCols = set()\n",
    "\n",
    "            # boucle sur la combinaison de l'index (ligne, colonne)\n",
    "            # tuples\n",
    "            for (row, col) in zip(rows, cols):\n",
    "                # si nous avons déjà examiné la ligne ou\n",
    "                # valeur de colonne avant, on l'ignore\n",
    "                if row in usedRows or col in usedCols:\n",
    "                    continue\n",
    "\n",
    "                # si la distance entre les points centraux est supérieure à\n",
    "                # la distance maximale, n'associez pas les deux\n",
    "                # centroids sur le même objet\n",
    "                if D[row, col] > self.maxDistance:\n",
    "                    continue\n",
    "\n",
    "                # sinon, récupérez l'ID objet de la ligne courante,\n",
    "                # définit son nouveau point central et réinitialise le\n",
    "                # compteur\n",
    "                objectID = objectIDs[row]\n",
    "                self.objects[objectID] = inputCentroids[col]\n",
    "                self.bbox[objectID] = inputRects[col]  # CHANGE\n",
    "                self.disappeared[objectID] = 0\n",
    "\n",
    "                # indique que nous avons examiné chacune des lignes et\n",
    "                # index de colonnes, respectivement\n",
    "                usedRows.add(row)\n",
    "                usedCols.add(col)\n",
    "\n",
    "            # calculer à la fois l'index de ligne et de colonne que nous n'avons PAS encore\n",
    "            # examiné\n",
    "            unusedRows = set(range(0, D.shape[0])).difference(usedRows)\n",
    "            unusedCols = set(range(0, D.shape[1])).difference(usedCols)\n",
    "\n",
    "            # dans le cas où le nombre de points central d'objet est\n",
    "            # égal ou supérieur au nombre du point central d'entrée\n",
    "            # nous devons vérifier et voir si certains de ces objets ont\n",
    "            # potentiellement disparu\n",
    "            if D.shape[0] >= D.shape[1]:\n",
    "                # boucle sur les index de ligne inutilisés\n",
    "                for row in unusedRows:\n",
    "                    # récupérer l'ID d'objet de la ligne correspondante\n",
    "                    # indexer et incrémenter le compteur disparu\n",
    "                    objectID = objectIDs[row]\n",
    "                    self.disappeared[objectID] += 1\n",
    "\n",
    "                    # vérifier si le nombre de\n",
    "                    # frames l'objet a été marqué \"disparu\"\n",
    "                    # pour les mandats de désenregistrement de l'objet\n",
    "                    if self.disappeared[objectID] > self.maxDisappeared:\n",
    "                        self.deregister(objectID)\n",
    "\n",
    "            # sinon, si le nombre des point centraux d'entrée est plus grand\n",
    "            # que le nombre des points centraux d'objets existants dont nous avons besoin\n",
    "            # enregistrer(register function) chaque nouveau point central d'entrée comme un objet traçable\n",
    "            else:\n",
    "                for col in unusedCols:\n",
    "                    self.register(inputCentroids[col], inputRects[col])\n",
    "\n",
    "        # renvoie l'ensemble des objets traçables\n",
    "        # return self.objects\n",
    "        return self.bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f4685ed8f087>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# on redimensionne l'image d'une largeur de 600 px\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# on increment total_frames de 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_frames\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# if both the width and height are None, then return the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f4685ed8f087>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# on redimensionne l'image d'une largeur de 600 px\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# on increment total_frames de 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_frames\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/imutils/convenience.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# grab the image size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# if both the width and height are None, then return the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
